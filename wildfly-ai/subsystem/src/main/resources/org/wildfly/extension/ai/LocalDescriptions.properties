#
# Copyright The WildFly Authors
# SPDX-License-Identifier: Apache-2.0
#

ai=The AI subsystem
ai.add=This operation adds the ai subsystem
ai.remove=This operation removes the ai subsystem

ai.embedding-store-content-retriever=A ContentRetriever that retrieves content from an embedding store.
ai.embedding-store-content-retriever.add=This operation adds an embedding store content retriever.
ai.embedding-store-content-retriever.embedding-model=Embedding model used to compute embeddings.
ai.embedding-store-content-retriever.embedding-store=Store were the contents and embeddings are retrieved from.
ai.embedding-store-content-retriever.filter=Filter to filter the retrieved contents
ai.embedding-store-content-retriever.min-score=The minimum relevance score for the returned contents.Contents scoring below this score are excluded from the results.
ai.embedding-store-content-retriever.max-results=The maximum number of contents to retrieve.
ai.embedding-store-content-retriever.remove=This operation removes an embedding store content retriever.

ai.in-memory-embedding-model=Embedding model for AI
ai.in-memory-embedding-model.add=This operation adds an embedding model
ai.in-memory-embedding-model.remove=This operation removes an embedding model
ai.in-memory-embedding-model.module=The module to load the embedding model from
ai.in-memory-embedding-model.embedding-class=The class from which the embedding model will be instanciated

ai.in-memory-embedding-store=In memory embedding store for AI.
ai.in-memory-embedding-store.add=This operation adds an in memory embedding store.
ai.in-memory-embedding-store.remove=This operation removes an in memory embedding store.
ai.in-memory-embedding-store.path=The actual filesystem path to be loaded as content of the in-memory embedding store. Treated as an absolute path, unless the 'relative-to' attribute is specified, in which case the value is treated as relative to that path.
ai.in-memory-embedding-store.relative-to=Reference to a filesystem path defined in the "paths" section of the server configuration.

ai.mistral-ai-chat-model=Chat model for Mitral AI
ai.mistral-ai-chat-model.add=This operation adds an Mitral AI chat model.
ai.mistral-ai-chat-model.remove=This operation removes an Mitral AI chat model.
ai.mistral-ai-chat-model.api-key=API key to authenticate to an Mitral AI chat model.
ai.mistral-ai-chat-model.base-url=Endpoint to connect to an Mitral AI chat model.
ai.mistral-ai-chat-model.connect-timeout=Timeout for the Mitral AI chat model.
ai.mistral-ai-chat-model.log-requests=Enabling the tracing of requests going to Mitral AI.
ai.mistral-ai-chat-model.log-responses=Enabling the tracing of responses from Mitral AI.
ai.mistral-ai-chat-model.max-token=The number of token retruned by the OpenAI chat model.
ai.mistral-ai-chat-model.model-name=Name of the model served by Mitral AI.
ai.mistral-ai-chat-model.response-format=The format of the response from Mitral AI.
ai.mistral-ai-chat-model.random-seed=Seed of the Mitral AI chat model.
ai.mistral-ai-chat-model.safe-prompt=Whether to inject a safety prompt before all conversations.
ai.mistral-ai-chat-model.temperature=Temperature of the Mitral AI chat model.
ai.mistral-ai-chat-model.top-p=Top P of the Mitral AI chat model.
ai.mistral-ai-chat-model.chat=Simple operation to send a user message to the LLM.
ai.mistral-ai-chat-model.chat.user-message=The user message sent to the LLM to test it

ai.ollama-chat-model=Chat model for AI for Ollama.
ai.ollama-chat-model.add=This operation adds a chat model
ai.ollama-chat-model.remove=This operation removes a chat model
ai.ollama-chat-model.base-url=Endpoint to connect to an Ollama chat model.
ai.ollama-chat-model.connect-timeout=Timeout for the Ollama chat model.
ai.ollama-chat-model.log-requests=Enabling the tracing of requests going to Ollama.
ai.ollama-chat-model.log-responses=Enabling the tracing of responses from Ollama.
ai.ollama-chat-model.max-retries==The maximum number of retries for API requests.
ai.ollama-chat-model.model-name=Name of the chat model served by Ollama.
ai.ollama-chat-model.response-format=The format of the response from Ollama.
ai.ollama-chat-model.temperature=Temperature of the Ollama chat model.
ai.ollama-chat-model.chat=Simple operation to send a user message to the LLM.
ai.ollama-chat-model.chat.user-message=The user message sent to the LLM to test it.

ai.ollama-embedding-model=Embedding model for AI for Ollama.
ai.ollama-embedding-model.add=This operation adds a embedding model
ai.ollama-embedding-model.remove=This operation removes a embedding model
ai.ollama-embedding-model.base-url=Endpoint to connect to an Ollama embedding model.
ai.ollama-embedding-model.connect-timeout=Timeout for the Ollama embedding model.
ai.ollama-embedding-model.log-requests=Enabling the tracing of requests going to Ollama.
ai.ollama-embedding-model.log-responses=Enabling the tracing of responses from Ollama.
ai.ollama-embedding-model.model-name=Name of the embedding model served by Ollama.

ai.openai-chat-model=Chat model for OpenAI
ai.openai-chat-model.add=This operation adds an OpenAI chat model.
ai.openai-chat-model.remove=This operation removes an OpenAI chat model.
ai.openai-chat-model.api-key=API key to authenticate to an OpenAI chat model.
ai.openai-chat-model.base-url=Endpoint to connect to an OpenAI chat model.
ai.openai-chat-model.connect-timeout=Timeout for the OpenAI chat model.
ai.openai-chat-model.frequency-penalty=Frequency penalty of the OpenAI chat model.
ai.openai-chat-model.log-requests=Enabling the tracing of requests going to OpenAI.
ai.openai-chat-model.log-responses=Enabling the tracing of responses from OpenAI.
ai.openai-chat-model.max-token=The number of token retruned by the OpenAI chat model.
ai.openai-chat-model.model-name=Name of the model served by OpenAI.
ai.openai-chat-model.organization-id=Name of the organization id served by OpenAI.
ai.openai-chat-model.presence-penalty=Presence penalty of the OpenAI chat model.
ai.openai-chat-model.response-format=The format of the response from OpenAI.
ai.openai-chat-model.seed=Seed of the OpenAI chat model.
ai.openai-chat-model.temperature=Temperature of the OpenAI chat model.
ai.openai-chat-model.top-p=Top P of the OpenAI chat model.
ai.openai-chat-model.chat=Simple operation to send a user message to the LLM.
ai.openai-chat-model.chat.user-message=The user message sent to the LLM to test it.

ai.weaviate-embedding-store=Weaviate embedding store for AI.
ai.weaviate-embedding-store.add=This operation adds a weaviate embedding store.
ai.weaviate-embedding-store.avoid-dups=If true the object id is a hashed ID based on provided text segment else a random ID will be generated.
ai.weaviate-embedding-store.remove=This operation removes a weaviate embedding store.
ai.weaviate-embedding-store.consistency-level=How the consistency is tuned when writting into weaviate embedding store.
ai.weaviate-embedding-store.metadata=The list of metadata keys to sotre with an embedding content.
ai.weaviate-embedding-store.object-class=The object class under which the embeddings are stored.
ai.weaviate-embedding-store.ssl-enabled=True if the connection to the Weaviate store is https or not.
ai.weaviate-embedding-store.socket-binding=The outbound socket binding to connect to the Weaviate store.

ai.web-search-content-retriever=Content retriever using web search results.
ai.web-search-content-retriever.max-results=The maximum number of results.
ai.web-search-content-retriever.google=The custom Google web search engine configuration.
ai.web-search-content-retriever.google.api-key=The Google Search API key for accessing the Google Custom Search API.
ai.web-search-content-retriever.google.connect-timeout=Timeout for the custom Google search.
ai.web-search-content-retriever.google.custom-search-id=The Custom Search ID parameter for search the entire web
ai.web-search-content-retriever.google.include-images=If it is true then include public images relevant to the query. This can add more latency to the search.
ai.web-search-content-retriever.google.log-requests=Whether to log API requests.
ai.web-search-content-retriever.google.log-responses=Whether to log API responses.
ai.web-search-content-retriever.google.max-retries=The maximum number of retries for API requests.
ai.web-search-content-retriever.google.site-restrict=If your Search Engine is restricted to only searching specific sites, you can set this parameter to true.
ai.web-search-content-retriever.tavily=The Tavily Search engine configuration.
ai.web-search-content-retriever.tavily.api-key=Your Tavily API key.
ai.web-search-content-retriever.tavily.base-url=The base url to access Tavily API.
ai.web-search-content-retriever.tavily.connect-timeout=Timeout for the Tavily API to respond.
ai.web-search-content-retriever.tavily.exclude-domains=A list of domains to specifically exclude from the search results.
ai.web-search-content-retriever.tavily.include-answer=Include answers in the search results.
ai.web-search-content-retriever.tavily.include-domains=A list of domains to specifically include in the search results.
ai.web-search-content-retriever.tavily.include-raw-content=Include raw content in the search results.
ai.web-search-content-retriever.tavily.search-depth=The depth of the search. It can be basic or advanced. Default is basic for quick results and advanced for indepth high quality results but longer response time. Advanced calls equals 2 requests.