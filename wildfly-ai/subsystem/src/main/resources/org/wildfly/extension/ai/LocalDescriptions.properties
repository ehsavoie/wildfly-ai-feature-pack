#
# Copyright The WildFly Authors
# SPDX-License-Identifier: Apache-2.0
#

ai=The AI subsystem
ai.add=This operation adds the ai subsystem
ai.remove=This operation removes the ai subsystem

ai.embedding-store-content-retriever=A ContentRetriever that retrieves content from an embedding store.
ai.embedding-store-content-retriever.add=This operation adds an embedding store content retriever.
ai.embedding-store-content-retriever.embedding-model=Embedding model used to compute embeddings.
ai.embedding-store-content-retriever.embedding-store=Store were the contents and embeddings are retrieved from.
ai.embedding-store-content-retriever.filter=Filter to filter the retrieved contents
ai.embedding-store-content-retriever.min-score=The minimum relevance score for the returned contents.Contents scoring below this score are excluded from the results.
ai.embedding-store-content-retriever.max-results=The maximum number of contents to retrieve.
ai.embedding-store-content-retriever.remove=This operation removes an embedding store content retriever.

ai.in-memory-embedding-model=Embedding model for AI
ai.in-memory-embedding-model.add=This operation adds an embedding model
ai.in-memory-embedding-model.remove=This operation removes an embedding model
ai.in-memory-embedding-model.module=The module to load the embedding model from
ai.in-memory-embedding-model.embedding-class=The class from which the embedding model will be instanciated

ai.in-memory-embedding-store=In memory embedding store for AI.
ai.in-memory-embedding-store.add=This operation adds an in memory embedding store.
ai.in-memory-embedding-store.remove=This operation removes an in memory embedding store.
ai.in-memory-embedding-store.path=The actual filesystem path to be loaded as content of the in-memory embedding store. Treated as an absolute path, unless the 'relative-to' attribute is specified, in which case the value is treated as relative to that path.
ai.in-memory-embedding-store.relative-to=Reference to a filesystem path defined in the "paths" section of the server configuration.

ai.mcp-client-sse=MCP SSE Client.
ai.mcp-client-sse.add=This operation adds a MCP SSE Client.
ai.mcp-client-sse.remove=This operation removes MCP SSE Client.
ai.mcp-client-sse.connect-timeout=Timeout for the MCP SSE client.
ai.mcp-client-sse.log-requests=Enabling the tracing of requests of the MCP SSE client.
ai.mcp-client-sse.log-responses=Enabling the tracing of responses of the MCP SSE client.
ai.mcp-client-sse.ssl-enabled=True if the connection to the he MCP server is https or not.
ai.mcp-client-sse.socket-binding=The outbound socket binding to connect to the MCP server.
ai.mcp-client-sse.sse-path=The URL path to append to access the SSEMCP server endpoint.

ai.mcp-client-stdio=MCP Stdio Client.
ai.mcp-client-stdio.add=This operation adds a MCP Stdio Client.
ai.mcp-client-stdio.remove=This operation removes MCP Stdio Client.
ai.mcp-client-stdio.cmd=The command to use to start the MCP Stdio server.
ai.mcp-client-stdio.args=The arguments to pass to the command to use to start the MCP Stdio server.

ai.mcp-tool-provider=Tool provider using MCP protocol.
ai.mcp-tool-provider.add=This operation adds a MCP Tool provider.
ai.mcp-tool-provider.remove=This operation removes a MCP Tool provider.
ai.mcp-tool-provider.mcp-clients=Lisrt of MCP clients used to provide tools.
ai.mcp-tool-provider.fail-if-one-server-fails= If this is true, then the tool provider will throw an exception if it fails to list tools from any of the servers otherwise the tool provider will ignore the error and continue with the next server.

ai.mistral-ai-chat-model=Chat model for Mitral AI
ai.mistral-ai-chat-model.add=This operation adds an Mitral AI chat model.
ai.mistral-ai-chat-model.remove=This operation removes an Mitral AI chat model.
ai.mistral-ai-chat-model.api-key=API key to authenticate to an Mitral AI chat model.
ai.mistral-ai-chat-model.base-url=Endpoint to connect to an Mitral AI chat model.
ai.mistral-ai-chat-model.connect-timeout=Timeout for the Mitral AI chat model.
ai.mistral-ai-chat-model.log-requests=Enabling the tracing of requests going to Mitral AI.
ai.mistral-ai-chat-model.log-responses=Enabling the tracing of responses from Mitral AI.
ai.mistral-ai-chat-model.max-token=The number of token retruned by the OpenAI chat model.
ai.mistral-ai-chat-model.model-name=Name of the model served by Mitral AI.
ai.mistral-ai-chat-model.response-format=The format of the response from Mitral AI.
ai.mistral-ai-chat-model.random-seed=Seed of the Mitral AI chat model.
ai.mistral-ai-chat-model.safe-prompt=Whether to inject a safety prompt before all conversations.
ai.mistral-ai-chat-model.streaming=Whether to create a token streaming chat language model or not.
ai.mistral-ai-chat-model.temperature=Temperature of the Mitral AI chat model.
ai.mistral-ai-chat-model.top-p=Top P of the Mitral AI chat model.
ai.mistral-ai-chat-model.chat=Simple operation to send a user message to the LLM.
ai.mistral-ai-chat-model.chat.user-message=The user message sent to the LLM to test it

ai.neo4j-embedding-store=Neo4J embedding store for AI.
ai.neo4j-embedding-store.add=This operation adds a Neo4J embedding store.
ai.neo4j-embedding-store.remove=This operation removes a Neo4J embedding store.
ai.neo4j-embedding-store.bolt-url=The Bolt URL to connect to the Neo4J server.
ai.neo4j-embedding-store.credential-reference=Credential (from Credential Store) to authenticate to Neo4J.
ai.neo4j-embedding-store.credential-reference.store=The name of the credential store holding the alias to credential
ai.neo4j-embedding-store.credential-reference.type=The type of credential this reference is denoting
ai.neo4j-embedding-store.credential-reference.alias=The alias which denotes stored secret or credential in the store
ai.neo4j-embedding-store.credential-reference.clear-text=Secret specified using clear text (check credential store way of supplying credential/secrets to services)
ai.neo4j-embedding-store.database-name=The Neo4J database name.
ai.neo4j-embedding-store.dimension=The dimension of the embedding.
ai.neo4j-embedding-store.embedding-property=The name of the property to store the embedding.
ai.neo4j-embedding-store.id-property=The optional id property name.
ai.neo4j-embedding-store.index-name=The optional index name.
ai.neo4j-embedding-store.label=The optional label name.
ai.neo4j-embedding-store.metadata-prefix=Tthe optional metadata prefix.
ai.neo4j-embedding-store.retrieval-query=The optional retrieval query 
ai.neo4j-embedding-store.text-property=The optional textProperty property name
ai.neo4j-embedding-store.username=The username to connect to Neo4J.

ai.ollama-chat-model=Chat model for AI for Ollama.
ai.ollama-chat-model.add=This operation adds a chat model
ai.ollama-chat-model.remove=This operation removes a chat model
ai.ollama-chat-model.base-url=Endpoint to connect to an Ollama chat model.
ai.ollama-chat-model.connect-timeout=Timeout for the Ollama chat model.
ai.ollama-chat-model.log-requests=Enabling the tracing of requests going to Ollama.
ai.ollama-chat-model.log-responses=Enabling the tracing of responses from Ollama.
ai.ollama-chat-model.max-retries==The maximum number of retries for API requests.
ai.ollama-chat-model.model-name=Name of the chat model served by Ollama.
ai.ollama-chat-model.response-format=The format of the response from Ollama.
ai.ollama-chat-model.streaming=Whether to create a token streaming chat language model or not.
ai.ollama-chat-model.temperature=Temperature of the Ollama chat model.
ai.ollama-chat-model.chat=Simple operation to send a user message to the LLM.
ai.ollama-chat-model.chat.user-message=The user message sent to the LLM to test it.

ai.ollama-embedding-model=Embedding model for AI for Ollama.
ai.ollama-embedding-model.add=This operation adds a embedding model
ai.ollama-embedding-model.remove=This operation removes a embedding model
ai.ollama-embedding-model.base-url=Endpoint to connect to an Ollama embedding model.
ai.ollama-embedding-model.connect-timeout=Timeout for the Ollama embedding model.
ai.ollama-embedding-model.log-requests=Enabling the tracing of requests going to Ollama.
ai.ollama-embedding-model.log-responses=Enabling the tracing of responses from Ollama.
ai.ollama-embedding-model.model-name=Name of the embedding model served by Ollama.

ai.openai-chat-model=Chat model for OpenAI
ai.openai-chat-model.add=This operation adds an OpenAI chat model.
ai.openai-chat-model.remove=This operation removes an OpenAI chat model.
ai.openai-chat-model.api-key=API key to authenticate to an OpenAI chat model.
ai.openai-chat-model.base-url=Endpoint to connect to an OpenAI chat model.
ai.openai-chat-model.connect-timeout=Timeout for the OpenAI chat model.
ai.openai-chat-model.frequency-penalty=Frequency penalty of the OpenAI chat model.
ai.openai-chat-model.log-requests=Enabling the tracing of requests going to OpenAI.
ai.openai-chat-model.log-responses=Enabling the tracing of responses from OpenAI.
ai.openai-chat-model.max-token=The number of token retruned by the OpenAI chat model.
ai.openai-chat-model.model-name=Name of the model served by OpenAI.
ai.openai-chat-model.organization-id=Name of the organization id served by OpenAI.
ai.openai-chat-model.presence-penalty=Presence penalty of the OpenAI chat model.
ai.openai-chat-model.response-format=The format of the response from OpenAI.
ai.openai-chat-model.seed=Seed of the OpenAI chat model.
ai.openai-chat-model.streaming=Whether to create a token streaming chat language model or not.
ai.openai-chat-model.temperature=Temperature of the OpenAI chat model.
ai.openai-chat-model.top-p=Top P of the OpenAI chat model.
ai.openai-chat-model.chat=Simple operation to send a user message to the LLM.
ai.openai-chat-model.chat.user-message=The user message sent to the LLM to test it.

ai.weaviate-embedding-store=Weaviate embedding store for AI.
ai.weaviate-embedding-store.add=This operation adds a weaviate embedding store.
ai.weaviate-embedding-store.avoid-dups=If true the object id is a hashed ID based on provided text segment else a random ID will be generated.
ai.weaviate-embedding-store.remove=This operation removes a weaviate embedding store.
ai.weaviate-embedding-store.consistency-level=How the consistency is tuned when writting into weaviate embedding store.
ai.weaviate-embedding-store.metadata=The list of metadata keys to sotre with an embedding content.
ai.weaviate-embedding-store.object-class=The object class under which the embeddings are stored.
ai.weaviate-embedding-store.ssl-enabled=True if the connection to the Weaviate store is https or not.
ai.weaviate-embedding-store.socket-binding=The outbound socket binding to connect to the Weaviate store.

ai.web-search-content-retriever=Content retriever using web search results.
ai.web-search-content-retriever.max-results=The maximum number of results.
ai.web-search-content-retriever.google=The custom Google web search engine configuration.
ai.web-search-content-retriever.google.api-key=The Google Search API key for accessing the Google Custom Search API.
ai.web-search-content-retriever.google.connect-timeout=Timeout for the custom Google search.
ai.web-search-content-retriever.google.custom-search-id=The Custom Search ID parameter for search the entire web
ai.web-search-content-retriever.google.include-images=If it is true then include public images relevant to the query. This can add more latency to the search.
ai.web-search-content-retriever.google.log-requests=Whether to log API requests.
ai.web-search-content-retriever.google.log-responses=Whether to log API responses.
ai.web-search-content-retriever.google.max-retries=The maximum number of retries for API requests.
ai.web-search-content-retriever.google.site-restrict=If your Search Engine is restricted to only searching specific sites, you can set this parameter to true.
ai.web-search-content-retriever.tavily=The Tavily Search engine configuration.
ai.web-search-content-retriever.tavily.api-key=Your Tavily API key.
ai.web-search-content-retriever.tavily.base-url=The base url to access Tavily API.
ai.web-search-content-retriever.tavily.connect-timeout=Timeout for the Tavily API to respond.
ai.web-search-content-retriever.tavily.exclude-domains=A list of domains to specifically exclude from the search results.
ai.web-search-content-retriever.tavily.include-answer=Include answers in the search results.
ai.web-search-content-retriever.tavily.include-domains=A list of domains to specifically include in the search results.
ai.web-search-content-retriever.tavily.include-raw-content=Include raw content in the search results.
ai.web-search-content-retriever.tavily.search-depth=The depth of the search. It can be basic or advanced. Default is basic for quick results and advanced for indepth high quality results but longer response time. Advanced calls equals 2 requests.